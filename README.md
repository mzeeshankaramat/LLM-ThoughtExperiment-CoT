# LLM Thought Experiment and CoT Comparison

## Overview
This repository contains the implementation and comparative analysis of methodologies from the paper "Let's Try Thought Experiment" in the context of Large Language Models (LLMs). The project focuses on comparing the Chain of Thought (CoT) and standard prompting techniques using the LLAMA-7b model.

## Model Used
- **LLAMA-7b**: A powerful 7 billion parameter model, utilized for its advanced language understanding and generation capabilities.

## Libraries
- **PyTorch**: An open-source machine learning library used for the implementation of the LLAMA-7b model.
- **Hugging Face Transformers**: Utilized for leveraging pre-trained models and applying transformer architectures easily.

## Reference Paper
The project is based on the paper titled "Let's Do a Thought Experiment: Using Counterfactuals to Improve Moral Reasoning". For detailed insights and methodology, refer to the paper available at [Let's Try Thought Experiment](https://arxiv.org/abs/2306.14308).
Also take a look on paper related to chain of thought prompting titled "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models". For detailed insights and methodology, refer to the paper available at [Chain of Thoughts](https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html).

## Implementation Details
The repository includes scripts and notebooks demonstrating the application of the "Let's Try Thought Experiment" methodology in LLMs. It also provides a comparative analysis with the Chain of Thought (CoT) and standard prompting techniques.

### How to Run
Install dependencies, and run the notebook.

